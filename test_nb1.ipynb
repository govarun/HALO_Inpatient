{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split \n",
    "from collections import defaultdict\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs Into Dataframes\n",
      "Building Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 454324/454324 [00:03<00:00, 149951.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190279\n",
      "VOCAB SIZE: 26164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mimic_dir = \"/srv/local/data/varun15/mimic4/\"\n",
    "admissionFile = mimic_dir + \"admissions.csv\"\n",
    "diagnosisFile = mimic_dir + \"diagnoses_icd.csv\"\n",
    "\n",
    "print(\"Loading CSVs Into Dataframes\")\n",
    "admissionDf = pd.read_csv(admissionFile, dtype=str)\n",
    "admissionDf['admittime'] = pd.to_datetime(admissionDf['admittime'])\n",
    "admissionDf = admissionDf.sort_values('admittime')\n",
    "admissionDf = admissionDf.reset_index(drop=True)\n",
    "diagnosisDf = pd.read_csv(diagnosisFile, dtype=str).set_index(\"hadm_id\")\n",
    "diagnosisDf = diagnosisDf[diagnosisDf['icd_code'].notnull()]\n",
    "diagnosisDf['icd_version_code'] = diagnosisDf['icd_version'] + \"_\" + diagnosisDf['icd_code']\n",
    "diagnosisDf =  diagnosisDf[[\"icd_version_code\"]]\n",
    "\n",
    "print(\"Building Dataset\")\n",
    "data = {}\n",
    "diagnosisDf_index_set = set(diagnosisDf.index)\n",
    "# Pre-process diagnosisDf into a dictionary\n",
    "diagnosis_dict = (diagnosisDf.groupby('hadm_id')['icd_version_code']\n",
    "                  .unique()\n",
    "                  .apply(list)\n",
    "                  .to_dict())\n",
    "# Using defaultdict to simplify data dictionary handling\n",
    "data = defaultdict(lambda: {'visits': []})\n",
    "all_diagnoses = set()\n",
    "for row in tqdm(admissionDf.itertuples(), total=admissionDf.shape[0]):          \n",
    "    #Extracting Admissions Table Info\n",
    "    hadm_id = row.hadm_id\n",
    "    subject_id = row.subject_id\n",
    "            \n",
    "    # Extracting the Diagnoses\n",
    "    diagnoses = diagnosis_dict.get(hadm_id, [])\n",
    "    all_diagnoses.update(diagnoses)\n",
    "    # Building the hospital admission data point\n",
    "    data[subject_id]['visits'].append(diagnoses)\n",
    "print(len(data))\n",
    "\n",
    "# converting the dict to a list, as the dict keys(subject_id) are no longer needed\n",
    "# subject_id was earlier needed to club the visits for a single patient\n",
    "data = list(data.values())\n",
    "\n",
    "# saved all the codes present in data[x]['visits'] in a dict and the reverse dict as well\n",
    "unique_codes = list(all_diagnoses)\n",
    "np.random.shuffle(unique_codes)\n",
    "code_to_index = {code: i for i, code in enumerate(unique_codes)}\n",
    "print(f\"VOCAB SIZE: {len(code_to_index)}\")\n",
    "index_to_code = {v: k for k, v in code_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Labels\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding Labels\")\n",
    "with open('icd_categories_groups.json', 'r') as file:\n",
    "    loaded_dict = json.load(file)\n",
    "\n",
    "icd9_categories = {ast.literal_eval(key): value for key, value in loaded_dict[\"icd9_categories\"].items()}\n",
    "icd10_categories = {ast.literal_eval(key): value for key, value in loaded_dict[\"icd10_categories\"].items()}\n",
    "group_disease_label_mapping = {ast.literal_eval(key): value for key, value in loaded_dict[\"group_disease_label_mapping\"].items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify an ICD-9 code\n",
    "def classify_icd9_code(icd9_code):\n",
    "    icd9_code = icd9_code[:3]\n",
    "    # Handle 'E' and 'V' codes separately\n",
    "    if icd9_code.startswith('E') or icd9_code.startswith('V'):\n",
    "        return 16\n",
    "    \n",
    "    # Convert the code to a float for comparison\n",
    "    try:\n",
    "        code = float(icd9_code)\n",
    "    except ValueError:\n",
    "        return 20\n",
    "\n",
    "    # Iterate through the map to find the matching category\n",
    "    for code_range, category in icd9_categories.items():\n",
    "        if code_range[0] <= code <= code_range[1]:\n",
    "            return category\n",
    "    \n",
    "    # If no category is found\n",
    "    return 20\n",
    "\n",
    "# Function to classify an ICD-10 code\n",
    "def classify_icd10_code(icd10_code):\n",
    "    # Extract the letter and the numeric part of the code\n",
    "    icd10_code = icd10_code[:3]\n",
    "\n",
    "    # Iterate through the map to find the matching category\n",
    "    for code_range, category in icd10_categories.items():\n",
    "        if code_range[0] <= icd10_code <= code_range[1]:\n",
    "            return category\n",
    "    # If no category is found\n",
    "    return 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_icd9_code(\"301\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visits': [['9_1598', '9_2851', '9_9974', '9_5601', '9_5859', '9_25001', '9_78057', '9_40390'], ['10_A419', '10_K3533', '10_R6521', '10_N179', '10_C49A3', '10_E871', '10_J90', '10_K660', '10_Z5331', '10_G4733', '10_E1065', '10_E1022', '10_E10649', '10_E10319', '10_E1021', '10_I129', '10_N189', '10_D649', '10_Z87891', '10_Z9641']]}\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190279/190279 [00:07<00:00, 26182.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding for the groups that have occurred for the current row\n",
    "# Add Labels\n",
    "for p in tqdm(data):\n",
    "  label = np.zeros(len(group_disease_label_mapping))\n",
    "  for v in p['visits']:\n",
    "    for c in v:\n",
    "      # print(c)\n",
    "      version, icd_code = c.split('_')\n",
    "      if int(version) == 9:\n",
    "        label[classify_icd9_code(icd_code)] = 1\n",
    "      else:\n",
    "        label[classify_icd10_code(icd_code)] = 1\n",
    "  # break\n",
    "  \n",
    "  p['labels'] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Visits\n"
     ]
    }
   ],
   "source": [
    "# here we are converting the visits from the codes to the indices we generated above.\n",
    "print(\"Converting Visits\")\n",
    "# converting all the codes to the indexes\n",
    "for p in data:\n",
    "    p['visits'] = [list(set(code_to_index[c] for c in v)) for v in p['visits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX LEN: 238\n",
      "AVG LEN: 2.387672838305856\n",
      "MAX VISIT LEN: 56\n",
      "AVG VISIT LEN: 11.019675385847986\n",
      "NUM RECORDS: 190279\n",
      "NUM LONGITUDINAL RECORDS: 83811\n",
      "Splitting Datasets\n",
      "Saving Everything\n",
      "26164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"MAX LEN: {max([len(p['visits']) for p in data])}\")\n",
    "print(f\"AVG LEN: {np.mean([len(p['visits']) for p in data])}\")\n",
    "print(f\"MAX VISIT LEN: {max([len(v) for p in data for v in p['visits']])}\")\n",
    "print(f\"AVG VISIT LEN: {np.mean([len(v) for p in data for v in p['visits']])}\")\n",
    "print(f\"NUM RECORDS: {len(data)}\")\n",
    "print(f\"NUM LONGITUDINAL RECORDS: {len([p for p in data if len(p['visits']) > 1])}\")\n",
    "\n",
    "# Train-Val-Test Split\n",
    "print(\"Splitting Datasets\")\n",
    "train_dataset, test_dataset = train_test_split(data, test_size=0.2, random_state=4, shuffle=True)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=4, shuffle=True)\n",
    "\n",
    "# Save Everything\n",
    "print(\"Saving Everything\")\n",
    "print(len(index_to_code))\n",
    "pickle.dump(code_to_index, open(\"./data/codeToIndex.pkl\", \"wb\"))\n",
    "pickle.dump(index_to_code, open(\"./data/indexToCode.pkl\", \"wb\"))\n",
    "pickle.dump(train_dataset, open(\"./data/trainDataset.pkl\", \"wb\"))\n",
    "pickle.dump(val_dataset, open(\"./data/valDataset.pkl\", \"wb\"))\n",
    "pickle.dump(test_dataset, open(\"./data/testDataset.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "halo1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
